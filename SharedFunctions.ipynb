{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsubapple/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3*x**2 + 4*y"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Symbolic partial differentiation -- examples\n",
    "from sympy import symbols, diff\n",
    "x, y, z = symbols('x y z', real=True)\n",
    "f = 4*x*y + x**3 + z**8*y\n",
    "diff(f, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1**2.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0, theta1, theta2, theta3, theta4, x0, x1 = symbols('theta0, theta1, theta2, theta3, theta4, x0, x1', real=True)\n",
    "g = theta0*x0 + theta1*x1 + theta2*x1**2 + theta3*x1**3 + theta4*x1**(2.5)\n",
    "diff(g, theta4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a data set and split it into training, cross-validation, and test data sets\n",
    "def splitDataSet(data, trainRatio, valRatio):\n",
    "    # Randomly shuffle the data -- \n",
    "    # Split up into train (trainRatio of all data), cross validate(valRatio), and test data sets\n",
    "    # NOTE - there's also a sklearn function train_test_split to do a similar thing but not quite\n",
    "    dataArr = np.array(data)\n",
    "    dataDim = dataArr.shape\n",
    "    #print dataArr[0:4,:]\n",
    "    np.random.shuffle(dataArr)\n",
    "    #print dataArr[0:4,:]\n",
    "\n",
    "    # Find out the number of data rows so they can be split up in the right proportion\n",
    "    num_train_rows = int(dataDim[0] * trainRatio)\n",
    "    num_val_rows = int(dataDim[0] * valRatio)\n",
    "    num_test_rows = dataDim[0] - (num_train_rows + num_val_rows)\n",
    "\n",
    "    # Training Data\n",
    "    X_train = dataArr[0:num_train_rows, 0].reshape((num_train_rows, 1))\n",
    "    y_train = dataArr[0:num_train_rows, 1].reshape((num_train_rows, 1))\n",
    "\n",
    "    # Cross Validation Data\n",
    "    X_val = dataArr[num_train_rows:num_train_rows + num_val_rows, 0].reshape((num_val_rows, 1))\n",
    "    y_val = dataArr[num_train_rows:num_train_rows + num_val_rows, 1].reshape((num_val_rows, 1))\n",
    "\n",
    "    # Test Data\n",
    "    X_test = dataArr[:num_test_rows, 0].reshape((num_test_rows, 1))\n",
    "    y_test = dataArr[:num_test_rows, 1].reshape((num_test_rows, 1))\n",
    "    \n",
    "    return [X_train, y_train, X_val, y_val, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeCost(X, y, theta):\n",
    "    # Cost of being wrong calculated over the entire data set\n",
    "    # Assumes that X has a first column of 1s added to it to simplify the notation\n",
    "    # Therefore: X is an m x n matrix and theta is a n x 1 matrix\n",
    "    \n",
    "    # costPerOutput is an m x 1 matrix where each element is the cost for\n",
    "    # the input and its associated output for a particular value of theta\n",
    "    costPerOutput = np.power(((X * theta) - y),2)\n",
    "    \n",
    "    # totalCost is the cost over the entire dataset\n",
    "    totalCost = np.sum(costPerOutput)\n",
    "    \n",
    "    # The cost of getting it wrong is 1/2m of the totalCost (normalized cost)\n",
    "    cost = totalCost / (2 * len(X))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement Gradient Descent\n",
    "def gradientDescent(X, y, theta, alpha, iters):\n",
    "    # NOTE: X must already have a column of 1s added to it\n",
    "    # X is a m x n matrix\n",
    "    # y is a m x 1 matrix\n",
    "    # Theta is a n x 1 matrix\n",
    "    \n",
    "    # Keep track of everything\n",
    "    sumError = np.zeros(shape=(len(theta),1))\n",
    "    sumErrorNorm = np.zeros(shape=(len(theta),1))\n",
    "    temp = np.matrix(np.zeros(theta.shape))\n",
    "    cost = np.zeros(iters)\n",
    "    \n",
    "    for i in range(iters):\n",
    "        # Calculate the non-normalized values for each theta parameter\n",
    "        error = (X * theta) - y\n",
    "        \n",
    "        for j in range(len(theta)):\n",
    "            # Multiply the error vector by the appropriate column of the X matrix and sum it\n",
    "            sumError[j] = np.sum(np.multiply(error, X[:,j]))\n",
    "            \n",
    "            # Normalize the sumError using alpha and m\n",
    "            sumErrorNorm[j] = np.divide(np.multiply(sumError[j], alpha), len(X))\n",
    "            \n",
    "            temp[j,0] = theta[j,0] - sumErrorNorm[j]\n",
    "        \n",
    "        theta = temp\n",
    "        cost[i] = computeCost(X,y,theta)\n",
    "            \n",
    "    \n",
    "    return theta, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the decision boundary\n",
    "# From Sebastian Raschka\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "    \n",
    "    # set up marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    \n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
    "    x2_min, x2_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
    "    \n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))\n",
    "    \n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    plt.xlabel('Exam 1 Score')\n",
    "    plt.ylabel('Exam 2 Score')\n",
    "    plt.title('Classifying the Data')\n",
    "    \n",
    "    # Plot all samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1], alpha=0.8, c=cmap(idx), marker=markers[idx], label=cl)\n",
    "    \n",
    "    return plt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the sigmoid function or transformation\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
